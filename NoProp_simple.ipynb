{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NoProp: Community Implementation\n",
        "Hyungon Ryu | Sr. Solution Architect | NVIDIA AI Technology Center Korea\n",
        "\n",
        "A community-driven reference implementation of the NoProp method described in Li et al., \"NoProp: Training Neural Networks without Back-propagation or Forward-propagation\" [arXiv:2503.24322v1](https://arxiv.org/html/2503.24322v1)\n",
        "\n",
        "## Overview\n",
        "\n",
        "NoProp is a novel approach for training neural networks without relying on standard back-propagation or forward-propagation steps. This repository provides:\n",
        " - Discrete-Time (DT) and Continuous-Time (CT) implementations.\n",
        " - Support for benchmark image classification tasks (MNIST, CIFAR-10, CIFAR-100).\n",
        " - Scripts for training, evaluation, and visualization of results.\n",
        "\n",
        "![Architecture](https://arxiv.org/html/2503.24322v1/extracted/6324620/plots/Noprop_clear.png)\n",
        "\n",
        "- Figure 1:Architecture of NoProp. $z_0$ represents Gaussian noise, while $z_1,…,z_T$ are successive transformations of $z_0$ through the learned dynamics $u_1,…,u_T$, with each layer conditioned on the image $x$, ultimately producing the class prediction $\\hat{y}$.\n",
        "\n",
        "![log](https://arxiv.org/html/2503.24322v1/extracted/6324620/plots/continuous_CIFAR-100.png)\n",
        "\n",
        "- Figure 3:Test accuracies (%) plotted against cumulative training time (in seconds) for models using one-hot label embedding in the continuous-time setting. All models within each plot were trained on the same type of GPU to ensure a fair comparison. NoProp-CT achieves strong performance in terms of both accuracy and speed compared to adjoint sensitivity. For CIFAR-100, NoProp-FM does not learn effectively with one-hot label embedding.\n",
        "\n",
        "for more detail, check the original paper [arXiv:2503.24322v1](https://arxiv.org/html/2503.24322v1)\n",
        "\n",
        "## implementation  \n",
        "- Modular Design: Duplicate paper and easily extend and investigate NoProp with different model architectures and datasets.\n",
        "- Modular Backbone Design: Easily configure ResNet-18, ResNet-50, or ResNet-152 backbones.\n",
        "- CLS Headers with time and Noise : Embed noise (Zt) and time-step (T), then fuse with feature header for classification.\n",
        "- continous train scheme : follow paper's train scheme with random T for continous train.\n",
        "- Scheduler Options: Support both Euler and Heun integration schemes for diffusion timesteps.\n",
        "- Evaluation Hooks:\n",
        "  - Automatic Heun integration with T=40 evaluation at the end of every epoch.\n",
        "  - Post-training evaluation across customizable T values (e.g., [2,5,10,20,40,60,100]).\n",
        "  - Benchmarks: Pre-configured for MNIST. you can easily evaluate for CIFAR-10, and CIFAR-100.\n",
        "\n"
      ],
      "metadata": {
        "id": "z3sRRNA9ZqV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/yhgon/NoProp.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvsbahjrZuEm",
        "outputId": "7b1fa0f4-4457-4f78-cacc-9747a75ff46e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NoProp'...\n",
            "remote: Enumerating objects: 60, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 60 (delta 16), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (60/60), 27.49 KiB | 3.44 MiB/s, done.\n",
            "Resolving deltas: 100% (16/16), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python NoProp/src/nopropct_mnist.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WINueqZBZuj-",
        "outputId": "9e46584b-c09c-4189-b118-70eddaa6145d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- resnet18 on cuda ---\n",
            "100% 9.91M/9.91M [00:00<00:00, 58.2MB/s]\n",
            "100% 28.9k/28.9k [00:00<00:00, 1.61MB/s]\n",
            "100% 1.65M/1.65M [00:00<00:00, 14.8MB/s]\n",
            "100% 4.54k/4.54k [00:00<00:00, 18.1MB/s]\n",
            "Epoch 01 loss 13.2554 | train 5.1s\n",
            "Epoch 02 loss 1.5875 | train 3.2s\n",
            "Epoch 03 loss 1.0001 | train 3.2s\n",
            "Epoch 04 loss 0.9099 | train 3.1s\n",
            "Epoch 05 loss 0.8535 | train 3.1s | Acc 95.83% | infer 5.4s\n",
            "Epoch 06 loss 0.9559 | train 3.0s\n",
            "Epoch 07 loss 0.8878 | train 2.9s\n",
            "Epoch 08 loss 0.8088 | train 2.8s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Citation\n",
        "```\n",
        "@misc{li2025noprop,\n",
        "  title={NoProp: Training Neural Networks without Back-propagation or Forward-propagation},\n",
        "  author={Li, Qinyu and Teh, Yee Whye and Pascanu, Razvan},\n",
        "  year={2025},\n",
        "  eprint={2503.24322v1},\n",
        "  archivePrefix={arXiv},\n",
        "  primaryClass={cs.LG}\n",
        "}\n",
        "```\n",
        "\n",
        "```\n",
        "@misc{ryu2025nopropcode,\n",
        "  title={NoProp: Community Implementation Code},\n",
        "  author={Ryu, Hyungon},\n",
        "  year={2025},\n",
        "  howpublished={\\url{https://github.com/yhgon/NoProp}}\n",
        "}\n",
        "```\n",
        "\n",
        "## log\n",
        "[train/eval for mnist](log01.md)\n",
        "\n"
      ],
      "metadata": {
        "id": "lrnO8FODZxlO"
      }
    }
  ]
}